{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing different Neural Networks\n",
    "\n",
    "Each Network uses a vector of the eigen-eigen parts and the eigenvalues and computes the rest-eigen contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LmaPredict, Flux, Statistics, Plots, Random, StatsBase, JLD2, PrettyTables, CSV, Tables, LaTeXStrings, Dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const path_config = \"/Users/lukasgeyer/Studium/Computational Sciences/Masterarbeit/Daten Simon/dat\"\n",
    "const path_plot = \"../plots\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = readdir(path_config)[2:5001]\n",
    "idx = sortperm( parse.(Int64, fname))\n",
    "fname = fname[idx]\n",
    "em_n = \"VV\"\n",
    "\n",
    "cnfgarr = Vector{LMAConfig}(undef, 0)\n",
    "for f in fname\n",
    "    push!(cnfgarr, get_LMAConfig(joinpath(path_config, f), \"g5-g5\", em=em_n, bc=false))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data in training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold = 10\n",
    "NCNFG = length(cnfgarr)\n",
    "train_size = 500\n",
    "test_size = NCNFG - train_size\n",
    "\n",
    "TSRC = \"24\"\n",
    "TVALS = length(cnfgarr[1].data[\"rr\"][TSRC]) - 1\n",
    "if em_n == \"PA\"\n",
    "    EIGVALS = 32\n",
    "else \n",
    "    EIGVALS = 64\n",
    "end\n",
    "\n",
    "eigvals_data_train = [Array{Float64}(undef, EIGVALS, train_size) for j in 1:k_fold]\n",
    "rr_data_train = [Array{Float64}(undef, TVALS, train_size) for j in 1:k_fold]\n",
    "ee_data_train = [Array{Float64}(undef, TVALS, train_size) for j in 1:k_fold]\n",
    "re_data_train = [Array{Float64}(undef, TVALS, train_size) for j in 1:k_fold]\n",
    "\n",
    "eigvals_data_test = [Array{Float64}(undef, EIGVALS, test_size) for j in 1:k_fold]\n",
    "rr_data_test = [Array{Float64}(undef, TVALS, test_size) for j in 1:k_fold]\n",
    "ee_data_test = [Array{Float64}(undef, TVALS, test_size) for j in 1:k_fold]\n",
    "re_data_test = [Array{Float64}(undef, TVALS, test_size) for j in 1:k_fold]\n",
    "\n",
    "for i in 1:k_fold\n",
    "    all_indexes = [index for index in 1:NCNFG]\n",
    "    train_start = ((i-1) * train_size) + 1\n",
    "    train_end = (train_start + train_size) - 1\n",
    "\n",
    "    for (k, dd) in enumerate(getfield.(cnfgarr, :data)[train_start:train_end])\n",
    "        \n",
    "        eigvals_data_train[i][:,k] = copy(cnfgarr[k].data[\"eigvals\"][1:EIGVALS])\n",
    "        \n",
    "        rr_data_train[i][:,k] = getindex(getindex(dd, \"rr\"), TSRC)[2:end]\n",
    "\n",
    "        re_data_train[i][:,k] = getindex(getindex(dd, \"re\"), TSRC)[2:end]\n",
    "    \n",
    "        ee_all_TSRC = Matrix{Float64}(undef, TVALS, TVALS)\n",
    "        for ee_TSRC in 0:TVALS-1\n",
    "            ee_all_TSRC[:,ee_TSRC+1] = getindex(getindex(dd, \"ee\"), \"$ee_TSRC\")[2:end]\n",
    "        end\n",
    "\n",
    "        ee_data_train[i][:,k] = mean(ee_all_TSRC, dims=2)\n",
    "        #ee_data_train[i][:,k] = getindex(getindex(dd, \"ee\"), TSRC)[2:end]\n",
    "    end\n",
    "    \n",
    "    for (k, dd) in enumerate(deleteat!(getfield.(cnfgarr, :data),[train_i for train_i in  train_start:train_end]))\n",
    "\n",
    "        eigvals_data_test[i][:,k] = copy(cnfgarr[k].data[\"eigvals\"][1:EIGVALS])\n",
    "\n",
    "        rr_data_test[i][:,k] = getindex(getindex(dd, \"rr\"), TSRC)[2:end]\n",
    "        \n",
    "        re_data_test[i][:,k] = getindex(getindex(dd, \"re\"), TSRC)[2:end]\n",
    "    \n",
    "        ee_all_TSRC = Matrix{Float64}(undef, TVALS, TVALS)\n",
    "        for ee_TSRC in 0:TVALS-1\n",
    "            ee_all_TSRC[:,ee_TSRC+1] = getindex(getindex(dd, \"ee\"), \"$ee_TSRC\")[2:end]\n",
    "        end\n",
    "\n",
    "        ee_data_test[i][:,k] = mean(ee_all_TSRC, dims=2)\n",
    "        #ee_data_test[i][:,k] = getindex(getindex(dd, \"ee\"), TSRC)[2:end]\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_length = 2\n",
    "output_length = 1\n",
    "\n",
    "input_shape_train = [Array{Matrix{Float64}}(undef, TVALS) for k in 1:k_fold]\n",
    "output_shape_train = [Array{Matrix{Float64}}(undef, TVALS) for k in 1:k_fold]\n",
    "input_shape_test = [Array{Matrix{Float64}}(undef, TVALS) for k in 1:k_fold]\n",
    "\n",
    "for k in 1:k_fold\n",
    "    for i in 1:TVALS\n",
    "        input_shape_train[k][i] = permutedims(hcat(ee_data_train[k][i,:], rr_data_train[k][i,:]))\n",
    "        output_shape_train[k][i] = permutedims(reshape(re_data_train[k][i,:], :, 1))\n",
    "        input_shape_test[k][i] = permutedims(hcat(ee_data_test[k][i,:], rr_data_test[k][i,:]))\n",
    "    end\n",
    "end\n",
    "\n",
    "output_shape_test = [re_data_test[k] for k in 1:k_fold];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_train_standardized = [Array{Matrix{Float64}}(undef, TVALS) for k in 1:k_fold]\n",
    "input_data_test_standardized = [Array{Matrix{Float64}}(undef, TVALS) for k in 1:k_fold]\n",
    "\n",
    "fir k in 1:k_fold\n",
    "    for i in 1:TVALS\n",
    "        mean_input_train = mean(input_shape_train[k][i], dims=ndims(input_shape_train[k][i]))\n",
    "        std_input_train = std(input_shape_train[k][i], dims=ndims(input_shape_train[k][i]))\n",
    "            \n",
    "        input_data_train_standardized[k][i] = (input_shape_train[k][i] .- mean_input_train) ./ std_input_train\n",
    "        input_data_test_standardized[k][i] = (input_shape_test[k][i] .- mean_input_train) ./ std_input_train\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data_train_standardized = [Array{Matrix{Float64}}(undef, TVALS) for k in 1:k_fold]\n",
    "\n",
    "for k in 1:k_fold\n",
    "    for i in 1:TVALS\n",
    "        mean_output_train = mean(output_shape_train[k][i])\n",
    "        std_output_train = std(output_shape_train[k][i])\n",
    "    \n",
    "        output_data_train_standardized[k][i] = (output_shape_train[k][i] .- mean_output_train) ./ std_output_train\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describing different Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_functions = [NNlib.tanh, NNlib.celu, NNlib.elu, NNlib.tanhshrink];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_perTimeSlice = []\n",
    "\n",
    "for activation_function in activation_functions\n",
    "    push!(models_perTimeSlice,\n",
    "        [\n",
    "    Chain(\n",
    "    Dense(input_length => output_length, identity),\n",
    "    ),\n",
    "    Chain(\n",
    "    Dense(input_length => 1, activation_function),\n",
    "    Dense(1 => output_length, identity),\n",
    "    ),\n",
    "    Chain(\n",
    "    Dense(input_length => 8, activation_function),\n",
    "    Dense(8 => 8, activation_function),\n",
    "    Dense(8 => 1, identity)\n",
    "    ),\n",
    "    Chain(\n",
    "    Dense(input_length => 50, activation_function),\n",
    "    Dense(50 => output_length, identity),\n",
    "    ),\n",
    "    Chain(\n",
    "    Dense(input_length => 100, activation_function),\n",
    "    Dense(100 => output_length, identity),\n",
    "    ),\n",
    "    Chain(\n",
    "    Dense(input_length => 400, activation_function),\n",
    "    Dropout(0.8),\n",
    "    Dense(400 => output_length, identity)\n",
    "    ),\n",
    "    Chain(\n",
    "    Dense(input_length => 600, activation_function),\n",
    "    Dropout(0.8),\n",
    "    Dense(600 => output_length, identity)\n",
    "    ),\n",
    "    Chain(\n",
    "    Dense(input_length => 800, activation_function),\n",
    "    Dropout(0.8),\n",
    "    Dense(800 => output_length, identity)\n",
    "    ),\n",
    "    Chain(\n",
    "    Dense(input_length => 1000, activation_function),\n",
    "    Dropout(0.8),\n",
    "    Dense(1000 => output_length, identity)\n",
    "    ),\n",
    "    Chain(\n",
    "    Dense(input_length => 1200, activation_function),\n",
    "    Dropout(0.8),\n",
    "    Dense(1200 => output_length, identity)\n",
    "    ),\n",
    "    Chain(\n",
    "    Dense(input_length => 50, activation_function),\n",
    "    Dense(50 => 1, activation_function),\n",
    "    Dense(1 => output_length, identity),\n",
    "    ),\n",
    "    Chain(\n",
    "    Dense(input_length => 50, activation_function),\n",
    "    Dense(50 => 50, activation_function),\n",
    "    Dense(50 => output_length, identity),\n",
    "    ),\n",
    "    Chain(\n",
    "    Dense(input_length => 100, activation_function),\n",
    "    Dense(100 => 50, activation_function),\n",
    "    Dense(50 => output_length, identity),\n",
    "    ),\n",
    "    Chain(\n",
    "    Dense(input_length => 100, activation_function),\n",
    "    Dense(100 => 100, activation_function),\n",
    "    Dense(100 => output_length, identity),\n",
    "    ),\n",
    "    Chain(\n",
    "    Dense(input_length => 400, activation_function),\n",
    "    Dropout(0.8),\n",
    "    Dense(400 => 200, activation_function),\n",
    "    Dropout(0.8),\n",
    "    Dense(200 => output_length, identity)\n",
    "    ),\n",
    "    Chain(\n",
    "    Dense(input_length => 600, activation_function),\n",
    "    Dropout(0.8),\n",
    "    Dense(600 => 400, activation_function),\n",
    "    Dropout(0.8),\n",
    "    Dense(400 => output_length, identity)\n",
    "    ),\n",
    "    Chain(\n",
    "    Dense(input_length => 800, activation_function),\n",
    "    Dropout(0.8),\n",
    "    Dense(800 => 600, activation_function),\n",
    "    Dropout(0.8),\n",
    "    Dense(600 => output_length, identity)\n",
    "    ),\n",
    "    Chain(\n",
    "    Dense(input_length => 1000, activation_function),\n",
    "    Dropout(0.8),\n",
    "    Dense(1000 => 800, activation_function),\n",
    "    Dropout(0.8),\n",
    "    Dense(800 => output_length, identity)\n",
    "    ),\n",
    "    Chain(\n",
    "    Dense(input_length => 50, activation_function),\n",
    "    Dense(50 => 50, activation_function),\n",
    "    Dense(50 => 50, activation_function),\n",
    "    Dense(50 => output_length, identity),\n",
    "    ),\n",
    "    Chain(\n",
    "    Dense(input_length => 100, activation_function),\n",
    "    Dense(100 => 100, activation_function),\n",
    "    Dense(100 => 100, activation_function),\n",
    "    Dense(100 => output_length, identity),\n",
    "    ),\n",
    "    Chain(\n",
    "    Dense(input_length => 400, activation_function),\n",
    "    Dropout(0.8),\n",
    "    Dense(400 => 400, activation_function),\n",
    "    Dropout(0.8),\n",
    "    Dense(400 => 400, activation_function),\n",
    "    Dropout(0.8),\n",
    "    Dense(400 => output_length, identity),\n",
    "    ),\n",
    "    Chain(\n",
    "    Dense(input_length => 600, activation_function),\n",
    "    Dropout(0.8),\n",
    "    Dense(600 => 600, activation_function),\n",
    "    Dropout(0.8),\n",
    "    Dense(600 => 600, activation_function),\n",
    "    Dropout(0.8),\n",
    "    Dense(600 => output_length, identity),\n",
    "    ),\n",
    "    Chain(\n",
    "    Dense(input_length => 800, activation_function),\n",
    "    Dropout(0.8),\n",
    "    Dense(800 => 800, activation_function),\n",
    "    Dropout(0.8),\n",
    "    Dense(800 => 800, activation_function),\n",
    "    Dropout(0.8),\n",
    "    Dense(800 => output_length, identity),\n",
    "    ),\n",
    "    Chain(\n",
    "    Dense(input_length => 1000, activation_function),\n",
    "    Dropout(0.8),\n",
    "    Dense(1000 => 1000, activation_function),\n",
    "    Dropout(0.8),\n",
    "    Dense(1000 => 1000, activation_function),\n",
    "    Dropout(0.8),\n",
    "    Dense(1000 => output_length, identity),\n",
    "    ),\n",
    "    Chain(\n",
    "    Dense(input_length => 400, activation_function),\n",
    "    Dropout(0.8),\n",
    "    Dense(400 => 200, activation_function),\n",
    "    Dropout(0.8),\n",
    "    Dense(200 => 200, activation_function),\n",
    "    Dropout(0.8),\n",
    "    Dense(200 => output_length, identity),\n",
    "    ),\n",
    "    Chain(\n",
    "    Dense(input_length => 600, activation_function),\n",
    "    Dropout(0.8),\n",
    "    Dense(600 => 400, activation_function),\n",
    "    Dropout(0.8),\n",
    "    Dense(400 => 400, activation_function),\n",
    "    Dropout(0.8),\n",
    "    Dense(400 => output_length, identity),\n",
    "    ),\n",
    "    Chain(\n",
    "    Dense(input_length => 800, activation_function),\n",
    "    Dropout(0.8),\n",
    "    Dense(800 => 600, activation_function),\n",
    "    Dropout(0.8),\n",
    "    Dense(600 => 600, activation_function),\n",
    "    Dropout(0.8),\n",
    "    Dense(600 => output_length, identity),\n",
    "    ),\n",
    "    Chain(\n",
    "    Dense(input_length => 1000, activation_function),\n",
    "    Dropout(0.8),\n",
    "    Dense(1000 => 800, activation_function),\n",
    "    Dropout(0.8),\n",
    "    Dense(800 => 800, activation_function),\n",
    "    Dropout(0.8),\n",
    "    Dense(800 => output_length, identity),\n",
    "    ),\n",
    "     ])\n",
    "end\n",
    "\n",
    "models_perTimeSlice = vcat(models_perTimeSlice...) |>f64;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describing parameter regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [1e-3];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = []\n",
    "push!(optimizers,[Flux.AdaGrad(), Flux.AdaDelta(), Flux.AMSGrad(), Flux.NAdam()])\n",
    "for learning_rate in learning_rates\n",
    "    push!(optimizers,\n",
    "        [\n",
    "            Flux.Adam(learning_rate),\n",
    "            Flux.RAdam(learning_rate),\n",
    "            Flux.AdaMax(learning_rate),\n",
    "            Flux.AdamW(learning_rate),\n",
    "            Flux.OAdam(learning_rate)\n",
    "            ])\n",
    "end\n",
    "optimizers = vcat(optimizers...);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function loss_mse(flux_model, x, y)\n",
    "    batch_size = size(x)[2]\n",
    "    ŷ = flux_model(x)\n",
    "    \n",
    "    return Flux.mse(ŷ, y, agg=sum)\n",
    "end\n",
    "\n",
    "function loss_mae(flux_model, x, y)\n",
    "    batch_size = size(x)[2]\n",
    "    ŷ = flux_model(x)\n",
    "    \n",
    "    return Flux.mae(ŷ, y, agg=sum)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_functions = [loss_mse, loss_mae]\n",
    "\n",
    "epochs = [150]\n",
    "\n",
    "batch_sizes = [64];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\"Model\", \"Optimizer\", \"Loss function\", \"Epoch\", \"Batch size\"];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_combinations = length(models_perTimeSlice) * length(loss_functions) * length(epochs) * length(batch_sizes) * length(optimizers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Matrix with all combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_date = now()\n",
    "\n",
    "output_directory = \"/Users/lukasgeyer/Studium/Computational Sciences/Masterarbeit/Tool Allesandro/repo/LmaPredict/gridSearch/eachTimeSlice/\"\n",
    "\n",
    "combination_matrix_name = output_directory * \"models_$curr_date.csv\"\n",
    "results_matrix_name = output_directory * \"results_$curr_date.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_combinations = length(models_perTimeSlice) * length(loss_functions) * length(epochs) * length(batch_sizes) * length(optimizers)\n",
    "combinations_matrix = Matrix{Any}(undef, n_combinations, length(variables))\n",
    "\n",
    "index = 1\n",
    "for model in models_perTimeSlice\n",
    "    for optimizer in optimizers\n",
    "        for loss_function in loss_functions\n",
    "            for epoch in epochs\n",
    "                for batch_size in batch_sizes\n",
    "                    combinations_matrix[index,:] = [model, optimizer, loss_function, epoch, batch_size]\n",
    "                    index +=1\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "CSV.write(combination_matrix_name, Tables.table(combinations_matrix), header=variables, delim=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perfoming Grid-Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_table_header = [\n",
    "    \"Index\",\n",
    "    \"Min(max. R-Score)\",\n",
    "    \"Avrg(max. R-Score)\",\n",
    "    \"Std(max. R-Score)\",\n",
    "    \"Avrg(epoch of max R-Score)\",\n",
    "    \"Std(epoch of max R-Score)\"\n",
    "]\n",
    "scores_mat = Matrix{Float64}(undef, n_combinations, length(scores_table_header))\n",
    "\n",
    "for i in 1:n_combinations\n",
    "    model_perTimeSlice = combinations_matrix[i,1] \n",
    "    optimizer = combinations_matrix[i,2]\n",
    "    loss_function = combinations_matrix[i,3]\n",
    "    epochs = combinations_matrix[i,4]\n",
    "    batch_size = combinations_matrix[i,5]\n",
    "\n",
    "    models = [model_perTimeSlice for i in 1:TVALS]\n",
    "\n",
    "    max_R = Array{Float64}(undef, k_fold)\n",
    "    epoch_of_max_R = Array{Float64}(undef, k_fold)\n",
    "    for k in 1:k_fold\n",
    "        mean_train = repeat(mean(re_data_train[k], dims=2), 1, test_size)\n",
    "    \n",
    "        Random.seed!(20)\n",
    "    \n",
    "        loaders = [Flux.DataLoader((input_data_train_standardized[k][i], output_data_train_standardized[k][i]),\n",
    "                batchsize=batch_size,\n",
    "                shuffle=true\n",
    "                ) for i in 1:TVALS]\n",
    "    \n",
    "    \n",
    "        R_scores = zeros(epochs)\n",
    "        function training()\n",
    "            losses = []\n",
    "            for epoch in 1:epochs\n",
    "                out_of_sample_predictions = Matrix{Float64}(undef, TVALS, test_size)\n",
    "                \n",
    "                for (i, model) in enumerate(models)\n",
    "                    optim = Flux.setup(optimizer, model)\n",
    "                    \n",
    "                    for (x, y) in loaders[i]\n",
    "                        grads = gradient(m -> loss_function(m, x, y), model)\n",
    "                        Flux.update!(optim, model, grads[1])\n",
    "                    end\n",
    "                end\n",
    "    \n",
    "                for j in 1:TVALS\n",
    "                    mean_output_train = mean(output_shape_train[k][j])\n",
    "                    std_output_train = std(output_shape_train[k][j])\n",
    "    \n",
    "                    out_of_sample_predictions[j,:] = (models[j](input_data_test_standardized[k][j]) .* std_output_train) .+ mean_output_train\n",
    "                end\n",
    "                \n",
    "                R_scores[epoch] = 1 - (Flux.mse(out_of_sample_predictions, output_shape_test, agg=sum) / Flux.mse(mean_train, output_shape_test, agg=sum))\n",
    "    \n",
    "            end\n",
    "        end\n",
    "    \n",
    "        training()\n",
    "    \n",
    "        max_R[k] = maximum(R_scores)\n",
    "        epoch_of_max_R[k] = argmax(R_scores)\n",
    "    end\n",
    "    \n",
    "    scores_mat[i,:] = [\n",
    "        i,\n",
    "        minimum(max_R),\n",
    "        mean(max_R),\n",
    "        std(max_R),\n",
    "        mean(epoch_of_max_R),\n",
    "        std(epoch_of_max_R)\n",
    "    ]\n",
    "end\n",
    "\n",
    "CSV.write(results_matrix_name, Tables.table(scores_mat), header=scores_table_header, delim=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV.write(results_matrix_name, Tables.table(scores_mat), header=scores_table_header, delim=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_mat = CSV.File(open(results_matrix_name); header=1, types=Float64) |> CSV.Tables.matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function getParams(model::Chain)\n",
    "    params = 0\n",
    "    for layer in model\n",
    "        params += sum(length, Flux.params(layer); init=0.0)\n",
    "    end\n",
    "\n",
    "    return params\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = map(model -> getParams(model), combinations_matrix[:,1])\n",
    "max_R = scores_mat[:,2]\n",
    "epoch_R = scores_mat[:,3]\n",
    "\n",
    "params_maxR_epochR_optimizer = hcat(hcat(hcat(params, max_R), epoch_R),combinations_matrix[:,2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_maxR_absSmallerTen = params_maxR_epochR_optimizer[(abs.(params_maxR_epochR_optimizer[:,2]) .< 10),:]\n",
    "params_maxR_biggerZero = params_maxR_epochR_optimizer[(params_maxR_epochR_optimizer[:,2] .> 0),:]\n",
    "\n",
    "scatter(params_maxR_biggerZero[:,1], params_maxR_biggerZero[:,2],\n",
    "    size=(1000,800),\n",
    "    xticks=([0,100_000,1_000_000,2_000_000],[\"0\", \"100_000\", \"1_000_000\", \"2_000_000\"]),\n",
    "    label=:false\n",
    ")\n",
    "xlabel!(\"Number of paramaters to train\")\n",
    "ylabel!(\"Maximum R Score\")\n",
    "\n",
    "#savefig(\"gridSearch.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optimizers[7]\n",
    "params_maxR_biggerZero_optimizer = permutedims(stack([params_maxR_biggerZero[i,:] for i=1:size(params_maxR_biggerZero)[1] if params_maxR_biggerZero[i,4] == optimizer]))\n",
    "\n",
    "scatter(params_maxR_biggerZero_optimizer[:,1], params_maxR_biggerZero_optimizer[:,2], size=(1000,800))\n",
    "xlabel!(\"Number of paramaters to train\")\n",
    "ylabel!(\"Maximum R Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_epochR_later130 = params_maxR_epochR[(params_maxR_epochR[:,3] .> 130),:]\n",
    "\n",
    "scatter(params_epochR_later130[:,1], params_epochR_later130[:,3], size=(1000,800))\n",
    "xlabel!(\"Number of paramaters to train\")\n",
    "ylabel!(\"Epoch of maximum R Score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_biggerZero = scores_mat[(scores_mat[:,2] .> 0),:]\n",
    "max_R = R_biggerZero[(R_biggerZero[:,2] .≈ maximum(R_biggerZero[:,2])), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#index = 2967\n",
    "index = Int(max_R[1])\n",
    "\n",
    "optimizer = combinations_matrix[index,2]\n",
    "loss_function = combinations_matrix[index,3]\n",
    "epochs = combinations_matrix[index, 4]\n",
    "batch_size = combinations_matrix[index, 5]\n",
    "\n",
    "epochMaxR = Int(scores_mat[index,3])\n",
    "model = combinations_matrix[index,1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Chain(\n",
    "  Dense(94 => 400, tanh),               # 38_000 parameters\n",
    "  Dropout(0.8),\n",
    "  Dense(400 => 47),                     # 18_847 parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(20)\n",
    "\n",
    "loader = Flux.DataLoader(\n",
    "    (input_data_train_standardized, output_data_train_standardized),\n",
    "    batchsize=batch_size,\n",
    "    shuffle=true\n",
    ")\n",
    "\n",
    "optim = Flux.setup(optimizer, model)\n",
    "\n",
    "R_scores = zeros(epochs)\n",
    "function training()\n",
    "    for e in 1:epochs\n",
    "        for (x,y) in loader\n",
    "            grads = gradient(m -> loss_function(m, x, y), model)\n",
    "            Flux.update!(optim, model, grads[1])\n",
    "        end\n",
    "        out_of_sample_predictions = (model(input_data_test_standardized) .* std_output_train) .+ mean_output_train\n",
    "        R_scores[e] = 1 - (Flux.mse(out_of_sample_predictions, output_shape_test, agg=sum) / Flux.mse(mean_train, output_shape_test, agg=sum))\n",
    "    end\n",
    "end\n",
    "\n",
    "losses = training()\n",
    "\n",
    "out_of_sample_predictions = (model(input_data_test_standardized) .* std_output_train) .+ mean_output_train\n",
    "R = 1 - (Flux.mse(out_of_sample_predictions, output_shape_test, agg=sum) / Flux.mse(mean_train, output_shape_test, agg=sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(R_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = @layout [a b c; d e f; g h i]\n",
    "\n",
    "c1 = rand([i for i in 1:500])\n",
    "p1 = scatter(output_shape_test[:,c1], label=\"Actual\")\n",
    "scatter!(p1, out_of_sample_predictions[:,c1], label=\"Prediction\", legend=:top)\n",
    "\n",
    "c2 = rand([i for i in 1:500])\n",
    "p2 = scatter(output_shape_test[:,c2], label=\"Actual\")\n",
    "scatter!(p2, out_of_sample_predictions[:,c2], label=\"Prediction\", legend=:top)\n",
    "\n",
    "c3 = rand([i for i in 1:500])\n",
    "p3 = scatter(output_shape_test[:,c3], label=\"Actual\")\n",
    "scatter!(p3, out_of_sample_predictions[:,c3], label=\"Prediction\", legend=:top, )\n",
    "\n",
    "c4 = rand([i for i in 1:500])\n",
    "p4 = scatter(output_shape_test[:,c4], label=\"Actual\")\n",
    "scatter!(p4, out_of_sample_predictions[:,c4], label=\"Prediction\", legend=:top)\n",
    "\n",
    "c5 = rand([i for i in 1:500])\n",
    "p5 = scatter(output_shape_test[:,c5], label=\"Actual\")\n",
    "scatter!(p5, out_of_sample_predictions[:,c5], label=\"Prediction\", legend=:top)\n",
    "\n",
    "c6 = rand([i for i in 1:500])\n",
    "p6 = scatter(output_shape_test[:,c6], label=\"Actual\")\n",
    "scatter!(p6, out_of_sample_predictions[:,c6], label=\"Prediction\", legend=:top)\n",
    "\n",
    "c7 = rand([i for i in 1:500])\n",
    "p7 = scatter(output_shape_test[:,c7], label=\"Actual\")\n",
    "scatter!(p7, out_of_sample_predictions[:,c7], label=\"Prediction\", legend=:top)\n",
    "\n",
    "c8 = rand([i for i in 1:500])\n",
    "p8 = scatter(output_shape_test[:,c8], label=\"Actual\")\n",
    "scatter!(p8, out_of_sample_predictions[:,c8], label=\"Prediction\", legend=:top)\n",
    "\n",
    "c9 = rand([i for i in 1:500])\n",
    "p9 = scatter(output_shape_test[:,c9], label=\"Actual\")\n",
    "scatter!(p9, out_of_sample_predictions[:,c9], label=\"Prediction\", legend=:top)\n",
    "\n",
    "plot(p1, p2, p3, p4, p5, p6, p7, p8, p9, layout = l, size=(1200,1000), dpi=1000, markerstrokewidth = 0)\n",
    "#savefig(joinpath(path_plot, \"neural_network_test.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_target = mean.([output_shape_test[i,:] for i in 1:TVALS])\n",
    "σ_target = std.([output_shape_test[i,:] for i in 1:TVALS]) ./ sqrt(test_size - 1)\n",
    "        \n",
    "mean_predicted = mean.([out_of_sample_predictions[i,:] for i in 1:TVALS])\n",
    "σ_predicted = std.([out_of_sample_predictions[i,:] for i in 1:TVALS]) ./ sqrt(test_size - 1)\n",
    "\n",
    "max_Δμ = maximum(abs.((mean_target - mean_predicted) ./ mean_target))\n",
    "\n",
    "p = scatter(\n",
    "        size=(1400,1000),\n",
    "        dpi = 1000,\n",
    "        thickness_scaling = 1.5,\n",
    ")\n",
    "    \n",
    "scatter!(p,\n",
    "    mean_target[7:41],\n",
    "    yerr=σ_target[7:41],\n",
    "    label=\"actual\",\n",
    "    legend=:bottom,\n",
    "    linecolor=:blue,\n",
    "    marker=:xcross,\n",
    "    markersize = 5,\n",
    "    markerstrokewidth = 0.3\n",
    ")\n",
    "scatter!(p,\n",
    "    mean_predicted[7:41],\n",
    "    yerr=σ_predicted[7:41],\n",
    "    label=\"predicted\",\n",
    "    legend=:bottom,\n",
    "    linecolor=:red,\n",
    "    marker =:+,\n",
    "    markersize = 5,\n",
    "    markerstrokewidth = 0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias-Correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying bias correction on a percentage of the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tests = 100\n",
    "percentages = [0.0, 0.01, 0.02, 0.04, 0.08, 0.1, 0.2]\n",
    "seeds = rand([i for i in 1:1_000_000], num_tests)\n",
    "\n",
    "for percentage in percentages\n",
    "    num_no_overlappings = zeros(num_tests)\n",
    "    χ²_s = zeros(num_tests)\n",
    "    χ²_train_s = zeros(num_tests)\n",
    "    i = 1\n",
    "    for test in 1:num_tests\n",
    "        n_configs = Int(test_size * percentage)\n",
    "\n",
    "        Random.seed!(seeds[test])\n",
    "        configs = sort!(sample([i for i in 1:test_size], n_configs, replace = false))\n",
    "        \n",
    "        uncorr_target_configs = stack(deleteat!([output_shape_test[:,i] for i in 1:test_size],configs), dims=2)\n",
    "        \n",
    "        mean_target = mean(uncorr_target_configs, dims=2)\n",
    "        σ_mean_target = std(uncorr_target_configs, dims=2) ./ sqrt(test_size - 1 - n_configs)\n",
    "\n",
    "        mean_target_train = mean(output_shape_train, dims=2)\n",
    "        σ_mean_target_train = std(output_shape_train, dims=2) ./ sqrt(train_size - 1)\n",
    "            \n",
    "        mean_predicted = mean(out_of_sample_predictions, dims=2)\n",
    "        σ_predicted = std(out_of_sample_predictions, dims=2) ./ sqrt(test_size - 1)\n",
    "        \n",
    "        if percentage > 0\n",
    "            bias_correction = mean(hcat([[out_of_sample_predictions[:,i] - output_shape_test[:,i] for i in configs][i] for i in 1:length(configs)]...), dims=2)\n",
    "            σ_bc = std(hcat([[out_of_sample_predictions[:,i] - output_shape_test[:,i] for i in configs][i] for i in 1:length(configs)]...), dims=2) ./ sqrt(n_configs - 1)\n",
    "            \n",
    "            mean_target_train = mean(hcat(output_shape_train, hcat([output_shape_test[:,i] for i in configs]...)), dims=2)\n",
    "            σ_mean_target_train = std(hcat(output_shape_train, hcat([output_shape_test[:,i] for i in configs]...)), dims=2) ./ sqrt(train_size + n_configs - 1)\n",
    "        else\n",
    "            bias_correction = zeros(output_length)\n",
    "            σ_bc = zeros(output_length)\n",
    "        end\n",
    "        \n",
    "        mean_predicted = mean_predicted - bias_correction\n",
    "        σ_pred_bc = σ_predicted + σ_bc\n",
    "        \n",
    "        χ²_s[i] = sum(((mean_predicted - mean_target) ./ sqrt.(σ_pred_bc.^2 + σ_mean_target.^2)).^2)\n",
    "        χ²_train_s[i] = sum(((mean_target_train - mean_target) ./ sqrt.(σ_mean_target_train.^2 + σ_mean_target.^2)).^2)\n",
    "\n",
    "        no_overlaps = 0\n",
    "        for t in 1:output_length\n",
    "            predicted_min = mean_predicted[t] - σ_pred_bc[t]\n",
    "            predicted_max = mean_predicted[t] + σ_pred_bc[t]\n",
    "        \n",
    "            target_min = mean_target[t] - σ_mean_target[t]\n",
    "            target_max = mean_target[t] + σ_mean_target[t]\n",
    "        \n",
    "            if predicted_min > target_max || predicted_max < target_min\n",
    "                no_overlaps += 1\n",
    "            end\n",
    "        end\n",
    "\n",
    "        num_no_overlappings[i] = no_overlaps\n",
    "        i += 1\n",
    "    end\n",
    "\n",
    "    mean_no_overlappings = mean(num_no_overlappings)\n",
    "    mean_χ² = mean(χ²_s)\n",
    "    maximum_χ² = maximum(χ²_s)\n",
    "    mean_χ²_train = mean(χ²_train_s)\n",
    "    maximum_χ²_train = maximum(χ²_train_s)\n",
    "    println(\"Percentage used for bias-correction: $percentage\")\n",
    "    println(\"Average number of non-overlappings: $mean_no_overlappings\")\n",
    "    println(\"<χ²>: $mean_χ², max χ²: $maximum_χ²\")\n",
    "    println(\"<χ²_train>: $mean_χ²_train, max χ²_train: $maximum_χ²_train\\n\")\n",
    "end     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_start = 8\n",
    "x_end = 40\n",
    "\n",
    "percentage = 0.1\n",
    "n_configs = Int(test_size * percentage)        \n",
    "configs = sort!(sample([i for i in 1:test_size], n_configs, replace = false))\n",
    "        \n",
    "uncorr_target_configs = stack(deleteat!([output_shape_test[:,i] for i in 1:test_size],configs), dims=2)\n",
    "        \n",
    "mean_target = mean(uncorr_target_configs, dims=2)\n",
    "σ_mean_target = std(uncorr_target_configs, dims=2) ./ sqrt(test_size - 1 - n_configs)\n",
    "\n",
    "mean_target_train = mean(output_shape_train, dims=2)\n",
    "σ_mean_target_train = std(output_shape_train, dims=2) ./ sqrt(train_size - 1)\n",
    "            \n",
    "mean_predicted = mean(out_of_sample_predictions, dims=2)\n",
    "σ_predicted = std(out_of_sample_predictions, dims=2) ./ sqrt(test_size - 1)\n",
    "        \n",
    "if percentage > 0\n",
    "    bias_correction = mean(hcat([[out_of_sample_predictions[:,i] - output_shape_test[:,i] for i in configs][i] for i in 1:length(configs)]...), dims=2)\n",
    "    σ_bc = std(hcat([[out_of_sample_predictions[:,i] - output_shape_test[:,i] for i in configs][i] for i in 1:length(configs)]...), dims=2) ./ sqrt(n_configs - 1)\n",
    "\n",
    "    mean_target_train = mean(hcat(output_shape_train,hcat([output_shape_test[:,i] for i in configs]...)), dims=2)\n",
    "    σ_mean_target_train = std(hcat(output_shape_train,hcat([output_shape_test[:,i] for i in configs]...)), dims=2) ./ sqrt(train_size + n_configs - 1)\n",
    "else\n",
    "    bias_correction = zeros(output_length)\n",
    "    σ_bc = zeros(output_length)\n",
    "end\n",
    "        \n",
    "mean_predicted = mean_predicted - bias_correction\n",
    "σ_pred_bc = σ_predicted + σ_bc\n",
    "\n",
    "no_overlaps = 0\n",
    "for t in 1:output_length\n",
    "    predicted_min = mean_predicted[t] - σ_pred_bc[t]\n",
    "    predicted_max = mean_predicted[t] + σ_pred_bc[t]\n",
    "        \n",
    "    target_min = mean_target[t] - σ_mean_target[t]\n",
    "    target_max = mean_target[t] + σ_mean_target[t]\n",
    "        \n",
    "    if predicted_min > target_max || predicted_max < target_min\n",
    "        println(\"Errors are not overlapping on t = $t\")\n",
    "    end\n",
    "end\n",
    "\n",
    "χ² = sum(((mean_predicted - mean_target) ./ sqrt.(σ_pred_bc.^2 + σ_mean_target.^2)).^2)\n",
    "χ²_train = sum(((mean_target_train - mean_target) ./ sqrt.(σ_mean_target_train.^2 + σ_mean_target.^2)).^2)\n",
    "println(\"χ² = \", χ²)\n",
    "println(\"χ²_train = \", χ²_train)\n",
    "\n",
    "p = scatter(\n",
    "    size=(1400,1000),\n",
    "    dpi = 1000,\n",
    "    thickness_scaling = 1.6,\n",
    "    title=\"bc: $n_configs\"\n",
    ")\n",
    "    \n",
    "#scatter!(p,\n",
    "#    mean_target[x_start:x_end],\n",
    "#    yerr=σ_mean_target[x_start:x_end],\n",
    "#    label=\"actual\",\n",
    "#    legend=:bottom,\n",
    "#    linecolor=:blue,\n",
    "#    marker=:xcross,\n",
    "#    markersize = 2,\n",
    "#    markerstrokewidth = 0.3,\n",
    "#    xticks=([i for i in 1:2:(x_end-x_start)+1],[\"$i\" for i in x_start:2:x_end])\n",
    "#)\n",
    "\n",
    "scatter!(p,\n",
    "    mean_predicted[x_start:x_end],\n",
    "    yerr=σ_pred_bc[x_start:x_end],\n",
    "    label=\"predicted\",\n",
    "    legend=:bottom,\n",
    "    linecolor=:red,\n",
    "    marker =:+,\n",
    "    markersize = 2,\n",
    "    markerstrokewidth = 0.3,\n",
    "    xticks=([i for i in 1:2:(x_end-x_start)+1],[\"$i\" for i in x_start:2:x_end])\n",
    ")\n",
    "\n",
    "scatter!(p,\n",
    "    mean_target_train[x_start:x_end],\n",
    "    yerr=σ_mean_target_train[x_start:x_end],\n",
    "    label=\"actual (training set)\",\n",
    "    legend=:bottom,\n",
    "    linecolor=:yellow,\n",
    "    marker=:xcross,\n",
    "    markersize = 2,\n",
    "    markerstrokewidth = 0.3,\n",
    "    xticks=([i for i in 1:2:(x_end-x_start)+1],[\"$i\" for i in x_start:2:x_end])\n",
    ")\n",
    "\n",
    "xlabel!(p,L\"t/a\")\n",
    "ylabel!(p,L\"C^{re}(x_0,y_0)\")\n",
    "#savefig(p,\"prediction_mean_bc.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.2",
   "language": "julia",
   "name": "julia-1.10.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
