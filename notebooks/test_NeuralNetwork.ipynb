{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying a Neural Network to predict the rest-eigen part from the eigenvalues and the eigen-eigen part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have an M-Series Apple chip available that has a perfomant GPU, you can use Metal for improving perfomance. Flux also supports CUDA if you wanna use it on NVIDIA GPU's. See [here](http://fluxml.ai/Flux.jl/stable/gpu/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LmaPredict, Flux, Metal, Statistics, ProgressMeter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check which GPU backend is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Metal\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Flux.GPU_BACKEND"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const path_config = \"/Users/lukasgeyer/Studium/Computational Sciences/Masterarbeit/Daten Simon/dat\"\n",
    "const path_plot = \"../plots\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = readdir(path_config)[2:5001]\n",
    "idx_cut = findall(x->x<=2500 , parse.(Int64, fname))\n",
    "fname = fname[idx_cut]\n",
    "idx = sortperm( parse.(Int64, fname))\n",
    "fname = fname[idx]\n",
    "\n",
    "cnfgarr = Vector{LMAConfig}(undef, 0)\n",
    "for f in fname\n",
    "    push!(cnfgarr, get_LMAConfig(joinpath(path_config, f), \"g5-g5\", em=\"PA\", bc=false))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data ind training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a specific Tsource and divide data into training and test set for rr re and ee components\n",
    "TSRC=\"12\"\n",
    "NCNFG = length(cnfgarr)\n",
    "TVALS = length(cnfgarr[1].data[\"rr\"][TSRC]) -1\n",
    "EIGVALS = minimum(length.([cnfgarr[i].data[\"eigvals\"] for i in 1:NCNFG]))\n",
    "\n",
    "eigvals_data = Array{Float64}(undef, EIGVALS, 2000)\n",
    "rr_data = Array{Float64}(undef, TVALS, 2000)\n",
    "ee_data = Array{Float64}(undef, TVALS, 2000)\n",
    "re_data = Array{Float64}(undef, TVALS, 2000)\n",
    "\n",
    "eigvals_data_test = Array{Float64}(undef, EIGVALS, 500)\n",
    "rr_data_test = Array{Float64}(undef, TVALS, 500)\n",
    "ee_data_test = Array{Float64}(undef, TVALS, 500)\n",
    "re_data_test = Array{Float64}(undef, TVALS, 500)\n",
    "\n",
    "\n",
    "for (k, dd) in enumerate(getfield.(cnfgarr, :data)[1:2000])\n",
    "    eigvals_data[:,k] = copy(cnfgarr[k].data[\"eigvals\"][1:EIGVALS])\n",
    "    rr_data[:,k] = getindex(getindex(dd, \"rr\"), TSRC)[2:end]\n",
    "    ee_data[:,k] = getindex(getindex(dd, \"ee\"), TSRC)[2:end]\n",
    "    re_data[:,k] = getindex(getindex(dd, \"re\"), TSRC)[2:end]\n",
    "end\n",
    "for (k, dd) in enumerate(getfield.(cnfgarr, :data)[2001:2500])\n",
    "    eigvals_data_test[:,k] = copy(cnfgarr[k].data[\"eigvals\"][1:EIGVALS])\n",
    "    rr_data_test[:,k] = getindex(getindex(dd, \"rr\"), TSRC)[2:end]\n",
    "    ee_data_test[:,k] = getindex(getindex(dd, \"ee\"), TSRC)[2:end]\n",
    "    re_data_test[:,k] = getindex(getindex(dd, \"re\"), TSRC)[2:end]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describing the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As input we choose a vector containing the inverted eigenvalues $\\lambda_i$ as the first $n_{\\lambda}$ entries, followed by the eigen-eigen contributions $ee_i$:\n",
    "\n",
    "$$ \n",
    "\n",
    "v_{input} = \\begin{bmatrix} \\ \\frac{1}{\\lambda_1} \\ \\\\[6pt] \\ \\frac{1}{\\lambda_2} \\ \\\\[6pt] \\ \\frac{1}{\\lambda_3} \\ \\\\[6pt] \\vdots \\\\[6pt] \\frac{1}{\\lambda_{n_{\\lambda}}} \\\\[6pt]\n",
    " \\ ee_1 \\ \\\\[6pt] \\ ee_2 \\ \\\\[6pt]\\ ee_3 \\ \\\\[6pt] \\vdots \\\\[6pt]\\ ee_{n_{ee}} \\ \\end{bmatrix}\n",
    "\n",
    "$$\n",
    " where $n_{ee}$ is the number of time samples, 47 in our case. $\\\\[10pt]$\n",
    "\n",
    "Our Neural Network therefore has an input layer of size $n_{\\lambda} + n_{ee}$. We then try one fully connected layer of size $2(n_{\\lambda} + n_{ee})$ and a fully connected output layer of size $n_{ee}$. \n",
    "\n",
    "**Note:** As we do not have the same amount of eigenvalues available for each configuration, we calculate the minimum of available eigenvalues out of all configurations, such that we can use as many as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_length = TVALS + EIGVALS\n",
    "output_length = TVALS\n",
    "hidden_length = 2 * input_length\n",
    "\n",
    "input_data = vcat(1 ./ eigvals_data, ee_data)\n",
    "target = re_data\n",
    "\n",
    "test_input_data = vcat(1 ./ eigvals_data_test,ee_data_test)\n",
    "test_target = re_data_test;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Chain(\n",
    "    Dense(input_length => hidden_length, tanh),\n",
    "    BatchNorm(hidden_length),\n",
    "    Dense(hidden_length => output_length),\n",
    "    softmax) |> gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining training input and target data\n",
    "\n",
    "We use a batch size of 64 configurations to introduce stochastivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = Flux.DataLoader((input_data, target) |> gpu, batchsize=64, shuffle=true)\n",
    "\n",
    "optim = Flux.setup(Flux.Adam(0.01), model);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Network\n",
    "\n",
    "The network sees $1000 \\cdot 64$ configurations. As loss function we use standard MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1_000\n",
    "\n",
    "losses = []\n",
    "@showprogress for epoch in 1:epochs\n",
    "    for (x, y) in loader\n",
    "        loss, grads = Flux.withgradient(model) do m\n",
    "            y_hat = m(x)\n",
    "            Flux.mse(y_hat, y)\n",
    "        end\n",
    "        Flux.update!(optim, model, grads[1])\n",
    "        push!(losses, loss) \n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking out-of-smaple results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_of_sample_predictions = model(test_input_data |> gpu) |> cpu;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Notice that I introduced a constant offset of $-0.021$ (which is arbitrary for now). There needs to be further investigation going into this offset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/Users/lukasgeyer/Studium/Computational Sciences/Masterarbeit/Tool Allesandro/repo/LmaPredict/plots/neural_network_test.pdf\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l = @layout [a b c; d e f; g h i]\n",
    "\n",
    "c1 = rand([i for i in 1:500])\n",
    "p1 = scatter(test_target[:,c1], label=\"Actual\")\n",
    "scatter!(p1, out_of_sample_predictions[:,c1] .- 2.1e-2, label=\"Prediction\", legend=:top)\n",
    "\n",
    "c2 = rand([i for i in 1:500])\n",
    "p2 = scatter(test_target[:,c2], label=\"Actual\")\n",
    "scatter!(p2, out_of_sample_predictions[:,c2] .- 2.1e-2, label=\"Prediction\", legend=:top)\n",
    "\n",
    "c3 = rand([i for i in 1:500])\n",
    "p3 = scatter(test_target[:,c3], label=\"Actual\")\n",
    "scatter!(p3, out_of_sample_predictions[:,c3] .- 2.1e-2, label=\"Prediction\", legend=:top, )\n",
    "\n",
    "c4 = rand([i for i in 1:500])\n",
    "p4 = scatter(test_target[:,c4], label=\"Actual\")\n",
    "scatter!(p4, out_of_sample_predictions[:,c4] .- 2.1e-2, label=\"Prediction\", legend=:top)\n",
    "\n",
    "c5 = rand([i for i in 1:500])\n",
    "p5 = scatter(test_target[:,c5], label=\"Actual\")\n",
    "scatter!(p5, out_of_sample_predictions[:,c5] .- 2.1e-2, label=\"Prediction\", legend=:top)\n",
    "\n",
    "c6 = rand([i for i in 1:500])\n",
    "p6 = scatter(test_target[:,c6], label=\"Actual\")\n",
    "scatter!(p6, out_of_sample_predictions[:,c6] .- 2.1e-2, label=\"Prediction\", legend=:top)\n",
    "\n",
    "c7 = rand([i for i in 1:500])\n",
    "p7 = scatter(test_target[:,c7], label=\"Actual\")\n",
    "scatter!(p7, out_of_sample_predictions[:,c7] .- 2.1e-2, label=\"Prediction\", legend=:top)\n",
    "\n",
    "c8 = rand([i for i in 1:500])\n",
    "p8 = scatter(test_target[:,c8], label=\"Actual\")\n",
    "scatter!(p8, out_of_sample_predictions[:,c8] .- 2.1e-2, label=\"Prediction\", legend=:top)\n",
    "\n",
    "c9 = rand([i for i in 1:500])\n",
    "p9 = scatter(test_target[:,c9], label=\"Actual\")\n",
    "scatter!(p9, out_of_sample_predictions[:,c9] .- 2.1e-2, label=\"Prediction\", legend=:top)\n",
    "\n",
    "plot(p1, p2, p3, p4, p5, p6, p7, p8, p9, layout = l, size=(1200,1000), dpi=1000, markerstrokewidth = 0)\n",
    "savefig(joinpath(path_plot, \"neural_network_test.pdf\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.4",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
