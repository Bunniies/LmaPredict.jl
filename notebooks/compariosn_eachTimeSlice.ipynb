{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing different Neural Networks\n",
    "\n",
    "In this notebook we use 47 Networks to predict the individual rest-eigen contributions on each time slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LmaPredict, Flux, Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"../plots\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const path_config = \"/Users/lukasgeyer/Studium/Computational Sciences/Masterarbeit/Daten Simon/dat\"\n",
    "const path_plot = \"../plots\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = readdir(path_config)[2:5001]\n",
    "idx = sortperm( parse.(Int64, fname))\n",
    "fname = fname[idx]\n",
    "em_n = \"VV\"\n",
    "\n",
    "cnfgarr = Vector{LMAConfig}(undef, 0)\n",
    "for f in fname\n",
    "    push!(cnfgarr, get_LMAConfig(joinpath(path_config, f), \"g5-g5\", em=em_n, bc=false))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data in training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NCNFG = length(cnfgarr)\n",
    "train_size = 500\n",
    "test_size = NCNFG - train_size\n",
    "\n",
    "TSRC = \"24\"\n",
    "TVALS = length(cnfgarr[1].data[\"rr\"][TSRC]) - 1\n",
    "if em_n == \"PA\"\n",
    "    EIGVALS = 32\n",
    "else \n",
    "    EIGVALS = 64\n",
    "end\n",
    "\n",
    "eigvals_data_train = Array{Float64}(undef, EIGVALS, train_size)\n",
    "rr_data_train = Array{Float64}(undef, TVALS, train_size)\n",
    "ee_data_train = Array{Float64}(undef, TVALS, train_size)\n",
    "re_data_train = Array{Float64}(undef, TVALS, train_size)\n",
    "\n",
    "eigvals_data_test = Array{Float64}(undef, EIGVALS, test_size)\n",
    "rr_data_test = Array{Float64}(undef, TVALS, test_size)\n",
    "ee_data_test = Array{Float64}(undef, TVALS, test_size)\n",
    "re_data_test = Array{Float64}(undef, TVALS, test_size)\n",
    "\n",
    "for (k, dd) in enumerate(getfield.(cnfgarr, :data)[1:train_size])\n",
    "    eigvals_data_train[:,k] = copy(cnfgarr[k].data[\"eigvals\"][1:EIGVALS])\n",
    "    rr_data_train[:,k] = getindex(getindex(dd, \"rr\"), TSRC)[2:end]\n",
    "    re_data_train[:,k] = getindex(getindex(dd, \"re\"), TSRC)[2:end]\n",
    "    \n",
    "    ee_all_TSRC = Matrix{Float64}(undef, TVALS, TVALS)\n",
    "    for ee_TSRC in 0:TVALS-1\n",
    "        ee_all_TSRC[:,ee_TSRC+1] = getindex(getindex(dd, \"ee\"), \"$ee_TSRC\")[2:end]\n",
    "    end\n",
    "    \n",
    "    ee_data_train[:,k] = mean(ee_all_TSRC, dims=2)\n",
    "end\n",
    "for (k, dd) in enumerate(getfield.(cnfgarr, :data)[train_size+1:NCNFG])\n",
    "    eigvals_data_test[:,k] = copy(cnfgarr[k].data[\"eigvals\"][1:EIGVALS])\n",
    "    rr_data_test[:,k] = getindex(getindex(dd, \"rr\"), TSRC)[2:end]\n",
    "    re_data_test[:,k] = getindex(getindex(dd, \"re\"), TSRC)[2:end]\n",
    "\n",
    "    ee_all_TSRC = Matrix{Float64}(undef, TVALS, TVALS)\n",
    "    for ee_TSRC in 0:TVALS-1\n",
    "        ee_all_TSRC[:,ee_TSRC+1] = getindex(getindex(dd, \"ee\"), \"$ee_TSRC\")[2:end]\n",
    "    end\n",
    "    \n",
    "    ee_data_test[:,k] = mean(ee_all_TSRC, dims=2)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_length = 2\n",
    "output_length = 1\n",
    "\n",
    "input_shape_train = Array{Matrix{Float64}}(undef, TVALS)\n",
    "output_shape_train = Array{Matrix{Float64}}(undef, TVALS)\n",
    "input_shape_test = Array{Matrix{Float64}}(undef, TVALS)\n",
    "\n",
    "for i in 1:TVALS\n",
    "    input_shape_train[i] = permutedims(hcat(ee_data_train[i,:], rr_data_train[i,:]))\n",
    "    output_shape_train[i] = permutedims(reshape(re_data_train[i,:], :, 1))\n",
    "    input_shape_test[i] = permutedims(hcat(ee_data_test[i,:], rr_data_test[i,:]))\n",
    "end\n",
    "\n",
    "output_shape_test = re_data_test;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input data, normalized and standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_train_normalized = Array{Matrix{Float64}}(undef, TVALS)\n",
    "input_data_train_standardized = Array{Matrix{Float64}}(undef, TVALS)\n",
    "input_data_test_normalized = Array{Matrix{Float64}}(undef, TVALS)\n",
    "input_data_test_standardized = Array{Matrix{Float64}}(undef, TVALS)\n",
    "\n",
    "for i in 1:TVALS\n",
    "    max_input_train = maximum(input_shape_train[i])\n",
    "    min_input_train = minimum(input_shape_train[i])\n",
    "\n",
    "    mean_input_train = mean(input_shape_train[i], dims=ndims(input_shape_train[i]))\n",
    "    std_input_train = std(input_shape_train[i], dims=ndims(input_shape_train[i]))\n",
    "\n",
    "    input_data_train_normalized[i] = (input_shape_train[i] .- max_input_train) ./ (max_input_train - min_input_train) \n",
    "    input_data_train_standardized[i] = (input_shape_train[i] .- mean_input_train) ./ std_input_train\n",
    "\n",
    "    input_data_test_normalized[i] = (input_shape_test[i] .- max_input_train) ./ (max_input_train - min_input_train)\n",
    "    input_data_test_standardized[i] = (input_shape_test[i] .- mean_input_train) ./ std_input_train\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output data, normalized and standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data_train_normalized = Array{Matrix{Float64}}(undef, TVALS)\n",
    "output_data_train_standardized = Array{Matrix{Float64}}(undef, TVALS)\n",
    "\n",
    "for i in 1:TVALS\n",
    "    max_output_train = maximum(output_shape_train[i])\n",
    "    min_output_train = minimum(output_shape_train[i])\n",
    "\n",
    "    mean_output_train = mean(output_shape_train[i])\n",
    "    std_output_train = std(output_shape_train[i])\n",
    "\n",
    "    output_data_train_normalized[i] = (output_shape_train[i] .- max_output_train) ./ (max_output_train - min_output_train)\n",
    "    output_data_train_standardized[i] = (output_shape_train[i] .- mean_output_train) ./ std_output_train\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describing different Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_function = NNlib.leakyrelu\n",
    "\n",
    "model = Chain(\n",
    "        Dense(input_length => 8, activation_function),\n",
    "        Dense(8 => 8, activation_function),\n",
    "        Dense(8 => 1, identity)\n",
    "    )\n",
    "\n",
    "models = [model for i in 1:TVALS] |> f64;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function loss(flux_model, x, y)\n",
    "    ŷ = flux_model(x)\n",
    "    Flux.mse(ŷ, y, agg=mean)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.747455019352072"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Flux:params\n",
    "\n",
    "mean_train = repeat(mean(re_data_train, dims=2), 1, test_size)\n",
    "\n",
    "optimizer = Flux.Adam(0.001)\n",
    "loss_function = Flux.mse\n",
    "loss_discription = \"MSE\"\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 10\n",
    "\n",
    "percentages_bc = [0.0, 0.01, 0.02, 0.05, 0.1, 0.12]\n",
    "n_configs_bc = Int.(test_size .* percentages_bc)\n",
    "\n",
    "loaders = [Flux.DataLoader((input_data_train_standardized[i], output_data_train_standardized[i]), batchsize=batch_size, shuffle=true) for i in 1:TVALS]\n",
    "\n",
    "parameters = 0\n",
    "layers = params(model)\n",
    "for layer in layers\n",
    "    parameters += length(hcat(layer...))\n",
    "end\n",
    "outputDirectory = \"/Users/lukasgeyer/Studium/Computational Sciences/Masterarbeit/Tool Allesandro/repo/LmaPredict/results/benchmarks/eachTimeSlice/$parameters\"\n",
    "\n",
    "model_losses = []\n",
    "for (i, model) in enumerate(models)\n",
    "\n",
    "    optim = Flux.setup(optimizer, model)\n",
    "    \n",
    "    function training()\n",
    "        losses = []\n",
    "        for epoch in 1:epochs\n",
    "            for (x, y) in loaders[i]\n",
    "                grads = gradient(m -> loss(m, x, y), model)\n",
    "                Flux.update!(optim, model, grads[1])\n",
    "                push!(losses, loss(model, x, y))\n",
    "            end\n",
    "        end\n",
    "        return losses\n",
    "    end\n",
    "\n",
    "    #training_time = @time training()\n",
    "    losses = training()\n",
    "    push!(model_losses, losses)\n",
    "    \n",
    "end\n",
    "\n",
    "out_of_sample_predictions = Matrix{Float64}(undef, TVALS, test_size)\n",
    "\n",
    "for i in 1:TVALS\n",
    "    mean_output_train = mean(output_shape_train[i])\n",
    "    std_output_train = std(output_shape_train[i])\n",
    "\n",
    "    out_of_sample_predictions[i,:] = (models[i](input_data_test_standardized[i]) .* std_output_train) .+ mean_output_train\n",
    "end\n",
    "\n",
    "\n",
    "analyse_predictions(\n",
    "        out_of_sample_predictions,\n",
    "        output_shape_test,\n",
    "        TSRC,\n",
    "        EIGVALS,\n",
    "        model,\n",
    "        optimizer,\n",
    "        loss_function,\n",
    "        loss_discription,\n",
    "        epochs,\n",
    "        batch_size,\n",
    "        model_losses[1],\n",
    "        outputDirectory\n",
    "    )\n",
    "\n",
    "R = 1 - (Flux.mse(out_of_sample_predictions, output_shape_test, agg=sum) / Flux.mse(mean_train, output_shape_test, agg=sum))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.2",
   "language": "julia",
   "name": "julia-1.10.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
