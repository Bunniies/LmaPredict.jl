{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing different Neural Networks\n",
    "\n",
    "In this notebook we use 47 Networks to predict the individual rest-eigen contributions on each time slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LmaPredict, Flux, Statistics, Plots, Random, StatsBase, JLD2, PrettyTables, TickTock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const path_config = \"/Users/lukasgeyer/Studium/Computational Sciences/Masterarbeit/Daten Simon/dat\"\n",
    "const path_plot = \"../plots\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = readdir(path_config)[2:5001]\n",
    "idx = sortperm( parse.(Int64, fname))\n",
    "fname = fname[idx]\n",
    "em_n = \"PA\"\n",
    "\n",
    "cnfgarr = Vector{LMAConfig}(undef, 0)\n",
    "for f in fname\n",
    "    push!(cnfgarr, get_LMAConfig(joinpath(path_config, f), \"g5-g5\", em=em_n, bc=false))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data in training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a specific Tsource and divide data into training and test set for eigenvalues, rr re and ee components\n",
    "TSRC = \"24\"\n",
    "NCNFG = length(cnfgarr)\n",
    "TVALS = length(cnfgarr[1].data[\"rr\"][TSRC]) - 1\n",
    "if em_n == \"PA\"\n",
    "    EIGVALS = 32\n",
    "else \n",
    "    EIGVALS = 64\n",
    "end\n",
    "\n",
    "eigvals_data_train = Array{Float32}(undef, EIGVALS, 500)\n",
    "rr_data_train = Array{Float32}(undef, TVALS, 500)\n",
    "ee_data_train = Array{Float32}(undef, TVALS, 500)\n",
    "re_data_train = Array{Float32}(undef, TVALS, 500)\n",
    "\n",
    "eigvals_data_test = Array{Float32}(undef, EIGVALS, 4500)\n",
    "rr_data_test = Array{Float64}(undef, TVALS, 4500)\n",
    "ee_data_test = Array{Float64}(undef, TVALS, 4500)\n",
    "re_data_test = Array{Float64}(undef, TVALS, 4500)\n",
    "\n",
    "for (k, dd) in enumerate(getfield.(cnfgarr, :data)[1:500])\n",
    "    eigvals_data_train[:,k] = copy(cnfgarr[k].data[\"eigvals\"][1:EIGVALS])\n",
    "    rr_data_train[:,k] = getindex(getindex(dd, \"rr\"), TSRC)[2:end]\n",
    "    ee_data_train[:,k] = getindex(getindex(dd, \"ee\"), TSRC)[2:end]\n",
    "    re_data_train[:,k] = getindex(getindex(dd, \"re\"), TSRC)[2:end]\n",
    "end\n",
    "for (k, dd) in enumerate(getfield.(cnfgarr, :data)[501:5000])\n",
    "    eigvals_data_test[:,k] = copy(cnfgarr[k].data[\"eigvals\"][1:EIGVALS])\n",
    "    rr_data_test[:,k] = getindex(getindex(dd, \"rr\"), TSRC)[2:end]\n",
    "    ee_data_test[:,k] = getindex(getindex(dd, \"ee\"), TSRC)[2:end]\n",
    "    re_data_test[:,k] = getindex(getindex(dd, \"re\"), TSRC)[2:end]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining and rescaling input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_length = EIGVALS + 2\n",
    "input_length = 2\n",
    "output_length = 1\n",
    "\n",
    "input_data_train = Array{Matrix}(undef, TVALS)\n",
    "means_data_train = Array{Float32}(undef, TVALS)\n",
    "std_data_train = Array{Float32}(undef, TVALS)\n",
    "for i in 1:TVALS \n",
    "    means_data_train[i] = mean([ee_data_train[i,:]'; rr_data_train[i,:]'])\n",
    "    std_data_train[i] = std([ee_data_train[i,:]'; rr_data_train[i,:]'])\n",
    "    input_data_train[i] = ([ee_data_train[i,:]'; rr_data_train[i,:]'] .- means_data_train[i]) ./ std_data_train[i]\n",
    "    \n",
    "    #means_data_train[i] = mean([1 ./ eigvals_data_train; ee_data_train[i,:]'; rr_data_train[i,:]'])\n",
    "    #std_data_train[i] = std([1 ./ eigvals_data_train; ee_data_train[i,:]'; rr_data_train[i,:]'])\n",
    "    #input_data_train[i] = ([1 ./ eigvals_data_train; ee_data_train[i,:]'; rr_data_train[i,:]'] .- means_data_train[i]) ./ std_data_train[i]\n",
    "end\n",
    "\n",
    "target_train = Array{Array}(undef, TVALS)\n",
    "for i in 1:TVALS\n",
    "    target_train[i] = re_data_train[i,:]'\n",
    "end\n",
    "\n",
    "input_data_test = Array{Matrix}(undef, TVALS)\n",
    "for i in 1:47\n",
    "    input_data_test[i] = ([ee_data_test[i,:]'; rr_data_test[i,:]'] .- means_data_train[i]) ./ std_data_train[i]\n",
    "    #input_data_test[i] = ([1 ./ eigvals_data_test; ee_data_test[i,:]'; rr_data_test[i,:]'] .- means_data_train[i]) ./ std_data_train[i]\n",
    "end\n",
    "\n",
    "target_test = Array{Array}(undef, TVALS)\n",
    "for i in 1:TVALS\n",
    "    target_test[i] = re_data_test[i,:]'\n",
    "end\n",
    "target_test = vcat(target_test...);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describing different Neural Networks\n",
    "\n",
    "We want to compare different Networks with respect to the parameters:\n",
    "\n",
    "- How many trainable variables has the Network?\n",
    "- How long does training take?\n",
    "- How good is the perfomance - measured by the standard deviation of the difference - with respect to\n",
    "     - How many configurations have been used for the bias correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_function = NNlib.elu\n",
    "\n",
    "models = [\n",
    "    [Chain(\n",
    "        Dense(input_length => 100, activation_function),\n",
    "        Dense(100 => 100, activation_function),\n",
    "        Dense(100 => 100, activation_function),\n",
    "        Dense(100 => output_length, activation_function),\n",
    "    ) for i in 1:TVALS]\n",
    "];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux:params\n",
    "\n",
    "optimizer = Flux.Adam(0.001)\n",
    "loss_function(x,y) = Flux.mse(x,y)\n",
    "loss_discription = \"MSE\"\n",
    "\n",
    "epochs = 50_000\n",
    "batch_size = 32\n",
    "\n",
    "loaders = [Flux.DataLoader((input_data_train[i], target_train[i]), batchsize=batch_size, shuffle=true) for i in 1:TVALS]\n",
    "\n",
    "for model in models\n",
    "    parameters = 0\n",
    "    layers = params(model)\n",
    "    for layer in layers\n",
    "        parameters += length(hcat(layer...))\n",
    "    end\n",
    "\n",
    "    output_dir = string(\"benchmarks/each_timeSlice/\", parameters)\n",
    "    mkpath(output_dir)\n",
    "    rm(output_dir * \"/results.txt\", force=true)\n",
    "\n",
    "    optim = [Flux.setup(optimizer, model[i]) for i in 1:TVALS]\n",
    "    \n",
    "    function training()\n",
    "        losses = Matrix{Float64}(undef, TVALS, Int(ceil(500 / batch_size))*epochs)\n",
    "        for (i, model_time) in enumerate(model)\n",
    "            j = 1\n",
    "            for epoch in 1:epochs\n",
    "                for (x, y) in loaders[i]\n",
    "                    loss, grads = Flux.withgradient(model_time) do m\n",
    "                        y_hat = m(x)\n",
    "                        loss_function(y_hat, y)\n",
    "                    end\n",
    "                    Flux.update!(optim[i], model_time, grads[1])\n",
    "                    losses[i,j] = loss \n",
    "                    j += 1\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        return losses\n",
    "    end\n",
    "\n",
    "    #training_time = @time training()\n",
    "    losses = training()\n",
    "    \n",
    "    minimum_training = minimum(losses)\n",
    "    maximum_training = maximum(losses)\n",
    "    average_training = mean(losses)\n",
    "\n",
    "    out_of_sample_predictions = vcat([model[i](input_data_test[i]) for i in 1:TVALS]...)\n",
    "    out_of_sample_error = [loss_function(out_of_sample_predictions[:,i], target_test[:,i]) for i in 1:4500]\n",
    "\n",
    "    c = 3333\n",
    "    p = scatter(target_test[:,c], label=\"Actual\")\n",
    "    scatter!(p, out_of_sample_predictions[:,c], label=\"Prediction\", legend=:top)\n",
    "    xaxis!(p,\"t\")\n",
    "    yaxis!(p,\"rest-eigen\")\n",
    "    savefig(p,output_dir * \"/sample.png\")\n",
    "\n",
    "    minimum_test = minimum(out_of_sample_error)\n",
    "    maximum_test = maximum(out_of_sample_error)\n",
    "    average_test = mean(out_of_sample_error)\n",
    "\n",
    "    open(output_dir * \"/results.txt\", \"a\") do file\n",
    "        println(file, \"Time source position: \", TSRC)\n",
    "        println(file, \"Number of used eigenvalues: \", EIGVALS, \"\\n\")\n",
    "\n",
    "        println(file, \"Optimizer: \", optimizer)\n",
    "        println(file, \"Loss function: \", loss_discription)\n",
    "        println(file, \"Epochs: \", epochs)\n",
    "        println(file, \"Batch size: \", batch_size, \"\\n\")\n",
    "        \n",
    "        println(file, \"Minimum training error (∑⁴⁷\", loss_discription, \"): \", minimum_training)\n",
    "        println(file, \"Maximum training error (∑⁴⁷\", loss_discription, \"): \", maximum_training)\n",
    "        println(file, \"Average training error (∑⁴⁷\", loss_discription, \"): \", average_training, \"\\n\")\n",
    "        \n",
    "        println(file, \"Minimum test error (∑⁴⁷\", loss_discription, \"): \",  minimum_test)\n",
    "        println(file, \"Maximum test error (∑⁴⁷\", loss_discription, \"): \", maximum_test)\n",
    "        println(file, \"Average test error (∑⁴⁷\", loss_discription, \"): \", average_test, \"\\n\")\n",
    "    end\n",
    "\n",
    "    percentages = [0.0, 0.01, 0.02, 0.05, 0.1, 0.12]\n",
    "    n_configs = Int.(4500 .* percentages)\n",
    "\n",
    "    header = [\n",
    "        \"Number of configs used for bc\",\n",
    "        \"|μ_diff/μ| (max)\",\n",
    "        \"|μ_diff/μ| (min)\",\n",
    "        \"|μ_diff/μ| (average)\",\n",
    "    ]\n",
    "\n",
    "    table = Matrix{Float64}(undef, length(percentages), length(header))\n",
    "\n",
    "    l = @layout [a b c; d e f]\n",
    "    \n",
    "    means_target = Matrix{Float64}(undef, TVALS, length(percentages_bc))\n",
    "    stds_target = Matrix{Float64}(undef, TVALS, length(percentages_bc))\n",
    "    \n",
    "    means_pred = Matrix{Float64}(undef, TVALS, length(percentages_bc))\n",
    "    stds_pred = Matrix{Float64}(undef, TVALS, length(percentages_bc))\n",
    "    \n",
    "    means_diff = Matrix{Float64}(undef, TVALS, length(percentages_bc))\n",
    "    stds_diff = Matrix{Float64}(undef, TVALS, length(percentages_bc))\n",
    "    \n",
    "    for (i,n) in enumerate(n_configs_bc)\n",
    "        Random.seed!(10)\n",
    "        configs = sort!(sample([i for i in 1:4500], n, replace = false))\n",
    "        \n",
    "        uncorr_target_configs = stack(deleteat!([target_test[:,i] for i in 1:4500],configs), dims=2)\n",
    "\n",
    "        mean_target = mean.([uncorr_target_configs[i,:] for i in 1:TVALS])\n",
    "        σ_mean_target = std.([uncorr_target_configs[i,:] for i in 1:TVALS])\n",
    "        \n",
    "        mean_predicted = mean.([out_of_sample_predictions[i,:] for i in 1:TVALS])\n",
    "\n",
    "        if n > 0\n",
    "            ias_correction = mean(hcat([[mean_predicted - target_test[:,i] for i in configs][i] for i in 1:length(configs)]...), dims=2)\n",
    "        else\n",
    "            bias_correction = zeros(TVALS)\n",
    "        end\n",
    "\n",
    "        mean_predicted = mean_predicted - bias_correction\n",
    "        σ_mean_predicted = std.([(out_of_sample_predictions .- bias_correction)[i,:] for i in 1:TVALS]) \n",
    "\n",
    "        mean_diff = (mean_target .- mean_predicted) ./ mean_target\n",
    "        σ_diff = sqrt.(sum.(hcat([((mean_target .- out_of_sample_predictions[:,i] - bias_correction) ./ mean_target).^2 for i in 1:4500]...)[k,:] for k in 1:TVALS) ./ (4500 - 1)) \n",
    "        \n",
    "        means_target[:,i] = mean_target\n",
    "        stds_target[:,i] = σ_mean_target\n",
    "        \n",
    "        means_pred[:,i] = mean_predicted\n",
    "        stds_pred[:,i] = σ_mean_predicted\n",
    "\n",
    "        means_diff[:,i] = mean_diff\n",
    "        stds_diff[:,i] = σ_diff\n",
    "\n",
    "        max_mean_diff = maximum(abs.(mean_diff))\n",
    "        min_mean_diff = minimum(abs.(mean_diff))\n",
    "        average_mean_diff = mean(abs.(mean_diff))\n",
    "\n",
    "        table[i,1] = n\n",
    "        table[i,2] = max_mean_diff\n",
    "        table[i,3] = min_mean_diff\n",
    "        table[i,4] = average_mean_diff\n",
    "    end\n",
    "\n",
    "    p = scatter(\n",
    "        means_diff,\n",
    "        yerr=stds_diff,\n",
    "        layout = l,\n",
    "        size=(1400,1000),\n",
    "        dpi = 1000,\n",
    "        legend=:false,\n",
    "        thickness_scaling = 1.1,\n",
    "        title=reshape([\"bc: $n\" for n in n_configs_bc],1,length(n_configs_bc)),\n",
    "        marker=:+,\n",
    "        markersize = 2,\n",
    "        markerstrokewidth = 0.3\n",
    "    )\n",
    "    savefig(p,output_dir * \"/mean_diff.png\")\n",
    "\n",
    "    p = scatter(\n",
    "        layout = l,\n",
    "        size=(1400,1000),\n",
    "        dpi = 1000,\n",
    "        thickness_scaling = 1.1,\n",
    "        title=reshape([\"bc: $n\" for n in n_configs_bc],1,length(n_configs_bc)))\n",
    "    \n",
    "    scatter!(p,\n",
    "        means_target,\n",
    "        label=\"actual\",\n",
    "        legend=:top,\n",
    "        linecolor=:blue,\n",
    "        marker=:xcross,\n",
    "        markersize = 2,\n",
    "        markerstrokewidth = 0.3\n",
    "    )\n",
    "    scatter!(p,\n",
    "        means_pred,\n",
    "        label=\"predicted\",\n",
    "        legend=:top,\n",
    "        linecolor=:red,\n",
    "        marker =:+,\n",
    "        markersize = 2,\n",
    "        markerstrokewidth = 0.3\n",
    "    )\n",
    "    savefig(p,output_dir * \"/mean.png\")\n",
    "\n",
    "    p = scatter(\n",
    "        layout = l,\n",
    "        size=(1400,1000),\n",
    "        dpi = 1000,\n",
    "        thickness_scaling = 1.1,\n",
    "        title=reshape([\"bc: $n\" for n in n_configs_bc],1,length(n_configs_bc)))\n",
    "    \n",
    "    scatter!(p,\n",
    "        means_target,\n",
    "        yerr=stds_target,\n",
    "        label=\"actual\",\n",
    "        legend=:top,\n",
    "        linecolor=:blue,\n",
    "        marker=:xcross,\n",
    "        markersize = 2,\n",
    "        markerstrokewidth = 0.3\n",
    "    )\n",
    "    scatter!(p,\n",
    "        means_pred,\n",
    "        yerr=stds_pred,\n",
    "        label=\"predicted\",\n",
    "        legend=:top,\n",
    "        linecolor=:red,\n",
    "        marker =:+,\n",
    "        markersize = 2,\n",
    "        markerstrokewidth = 0.3\n",
    "    )\n",
    "    savefig(p,output_dir * \"/mean_errorbar.png\")\n",
    "\n",
    "    open(output_dir * \"/results.txt\", \"a\") do file\n",
    "        pretty_table(file, table, header=header)\n",
    "        println(file)\n",
    "        println(file, \"Model: \", model)\n",
    "    end\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.0",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
